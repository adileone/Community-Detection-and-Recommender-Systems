{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ItemID', 'Sentiment', 'SentimentText']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "tweets = pd.read_csv(\"/media/alessandro/storage/Tesi/locale/twitter-sentiment-analysis2/train.csv\", encoding='latin-1')\n",
    "list(tweets.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.Sentiment.replace(0,'negative', inplace=True)\n",
    "tweets.Sentiment.replace(1,'positive', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ItemID</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>SentimentText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>negative</td>\n",
       "      <td>is so sad for my APL frie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>negative</td>\n",
       "      <td>I missed the New Moon trail...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>positive</td>\n",
       "      <td>omg its already 7:30 :O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>negative</td>\n",
       "      <td>.. Omgaga. Im sooo  im gunna CRy. I'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>negative</td>\n",
       "      <td>i think mi bf is cheating on me!!!   ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ItemID Sentiment                                      SentimentText\n",
       "0       1  negative                       is so sad for my APL frie...\n",
       "1       2  negative                     I missed the New Moon trail...\n",
       "2       3  positive                            omg its already 7:30 :O\n",
       "3       4  negative            .. Omgaga. Im sooo  im gunna CRy. I'...\n",
       "4       5  negative           i think mi bf is cheating on me!!!   ..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive    56457\n",
      "negative    43532\n",
      "Name: Sentiment, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "sentiment_counts = tweets.Sentiment.value_counts()\n",
    "number_of_tweets = tweets.ItemID.count()\n",
    "print(sentiment_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def normalizer(tweet):\n",
    "    only_letters = re.sub(\"[^a-zA-Z]\", \" \",tweet) \n",
    "    tokens = nltk.word_tokenize(only_letters)[2:]\n",
    "    lower_case = [l.lower() for l in tokens]\n",
    "    filtered_result = list(filter(lambda l: l not in stop_words, lower_case))\n",
    "    lemmas = [wordnet_lemmatizer.lemmatize(t) for t in filtered_result]\n",
    "    return lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['text', 'airline', 'like']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalizer(\"Here is text about an airline I like.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SentimentText</th>\n",
       "      <th>normalized_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>is so sad for my APL friend.............</td>\n",
       "      <td>[sad, apl, friend]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I missed the New Moon trailer...</td>\n",
       "      <td>[new, moon, trailer]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>omg its already 7:30 :O</td>\n",
       "      <td>[already]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>.. Omgaga. Im sooo  im gunna CRy. I've been at this dentist since 11.. I was suposed 2 just get a crown put on (30mins)...</td>\n",
       "      <td>[sooo, im, gunna, cry, dentist, since, suposed, get, crown, put, min]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i think mi bf is cheating on me!!!       T_T</td>\n",
       "      <td>[mi, bf, cheating]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                          SentimentText  \\\n",
       "0                       is so sad for my APL friend.............                                                                          \n",
       "1                     I missed the New Moon trailer...                                                                                    \n",
       "2                omg its already 7:30 :O                                                                                                  \n",
       "3            .. Omgaga. Im sooo  im gunna CRy. I've been at this dentist since 11.. I was suposed 2 just get a crown put on (30mins)...   \n",
       "4           i think mi bf is cheating on me!!!       T_T                                                                                  \n",
       "\n",
       "                                                        normalized_tweet  \n",
       "0  [sad, apl, friend]                                                     \n",
       "1  [new, moon, trailer]                                                   \n",
       "2  [already]                                                              \n",
       "3  [sooo, im, gunna, cry, dentist, since, suposed, get, crown, put, min]  \n",
       "4  [mi, bf, cheating]                                                     "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', -1) # Setting this so we can see the full content of cells\n",
    "tweets['normalized_tweet'] = tweets.SentimentText.apply(normalizer)\n",
    "tweets[['SentimentText','normalized_tweet']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>grams</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[sad apl, apl friend, sad apl friend]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[new moon, moon trailer, new moon trailer]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[sooo im, im gunna, gunna cry, cry dentist, dentist since, since suposed, suposed get, get crown, crown put, put min, sooo im gunna, im gunna cry, gunna cry dentist, cry dentist since, dentist since suposed, since suposed get, suposed get crown, get crown put, crown put min]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[mi bf, bf cheating, mi bf cheating]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                 grams\n",
       "0  [sad apl, apl friend, sad apl friend]                                                                                                                                                                                                                                              \n",
       "1  [new moon, moon trailer, new moon trailer]                                                                                                                                                                                                                                         \n",
       "2  []                                                                                                                                                                                                                                                                                 \n",
       "3  [sooo im, im gunna, gunna cry, cry dentist, dentist since, since suposed, suposed get, get crown, crown put, put min, sooo im gunna, im gunna cry, gunna cry dentist, cry dentist since, dentist since suposed, since suposed get, suposed get crown, get crown put, crown put min]\n",
       "4  [mi bf, bf cheating, mi bf cheating]                                                                                                                                                                                                                                               "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import ngrams\n",
    "def ngrams(input_list):\n",
    "    #onegrams = input_list\n",
    "    bigrams = [' '.join(t) for t in list(zip(input_list, input_list[1:]))]\n",
    "    trigrams = [' '.join(t) for t in list(zip(input_list, input_list[1:], input_list[2:]))]\n",
    "    return bigrams+trigrams\n",
    "tweets['grams'] = tweets.normalized_tweet.apply(ngrams)\n",
    "tweets[['grams']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "def count_words(input):\n",
    "    cnt = collections.Counter()\n",
    "    for row in input:\n",
    "        for word in row:\n",
    "            cnt[word] += 1\n",
    "    return cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('gon na', 587),\n",
       " ('wan na', 531),\n",
       " ('wish could', 308),\n",
       " ('last night', 300),\n",
       " ('twitpic com', 262),\n",
       " ('got ta', 223),\n",
       " ('sorry hear', 194),\n",
       " ('feel better', 187),\n",
       " ('bit ly', 186),\n",
       " ('look like', 184),\n",
       " ('feel like', 182),\n",
       " ('http bit', 168),\n",
       " ('http bit ly', 166),\n",
       " ('na go', 150),\n",
       " ('oh well', 132),\n",
       " ('want go', 126),\n",
       " ('next week', 113),\n",
       " ('miss u', 110),\n",
       " ('get better', 109),\n",
       " ('make sad', 105)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets[(tweets.Sentiment == 'negative')][['grams']].apply(count_words)['grams'].most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('twitpic com', 658),\n",
       " ('gon na', 527),\n",
       " ('bit ly', 444),\n",
       " ('http bit', 395),\n",
       " ('http bit ly', 395),\n",
       " ('wan na', 307),\n",
       " ('good luck', 236),\n",
       " ('last night', 221),\n",
       " ('tinyurl com', 212),\n",
       " ('got ta', 210),\n",
       " ('let know', 208),\n",
       " ('quot quot', 207),\n",
       " ('http tinyurl', 202),\n",
       " ('http tinyurl com', 200),\n",
       " ('com add', 184),\n",
       " ('day using', 182),\n",
       " ('using www', 182),\n",
       " ('add everyone', 182),\n",
       " ('everyone train', 182),\n",
       " ('train pay', 182)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets[(tweets.Sentiment == 'positive')][['grams']].apply(count_words)['grams'].most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vectorizer = CountVectorizer(ngram_range=(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized_data = count_vectorizer.fit_transform(tweets.SentimentText)\n",
    "indexed_data = hstack((np.array(range(0,vectorized_data.shape[0]))[:,None], vectorized_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment2target(sentiment):\n",
    "    return {\n",
    "        'negative': 0,\n",
    "        'neutral': 1,\n",
    "        'positive' : 2\n",
    "    }[sentiment]\n",
    "targets = tweets.Sentiment.apply(sentiment2target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "data_train, data_test, targets_train, targets_test = train_test_split(indexed_data, targets, test_size=0.3, random_state=0)\n",
    "data_train_index = data_train[:,0]\n",
    "data_train = data_train[:,1:]\n",
    "data_test_index = data_test[:,0]\n",
    "data_test = data_test[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "clf = OneVsRestClassifier(svm.SVC(gamma='scale', C=50, probability=True, kernel='linear', verbose=True))\n",
    "clf_output = clf.fit(data_train, targets_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
